server.port=8005
spring.application.name=lead-crawl-service
spring.datasource.driver-class-name=org.mariadb.jdbc.Driver
spring.datasource.host=localhost
spring.datasource.url=jdbc:mariadb://${spring.datasource.host}:3306/AUTOMI_CRAWLER
spring.datasource.username=automi_crawler_admin
spring.datasource.password=automi_crawler_admin
logging.config=config/logback-spring.xml
logback.access.config=config/logback-access-spring.xml
logging.level.org.springframework.jdbc.core=TRACE
logging.path=./logs
spring.redis.host=127.0.0.1
chrome.driver.path=config/chromedriver
aws.bucket.name=company-crawler-check
aws.bucket.name.input=company-crawler-check/LEAD_CRAWL_CSV/TEST_INPUT
aws.bucket.name.output=company-crawler-check/LEAD_CRAWL_CSV/OUTPUT
aws.bucket.name.complete=company-crawler-check/LEAD_CRAWL_CSV/COMPLETED
aws.bucket.name.process=company-crawler-check/LEAD_CRAWL_CSV/PROCESSED
aws.bucket.name.payload=company-crawler-check/LEAD_CRAWL_CSV/snurl
aws.bucket.name.final.output=company-crawler-check/LEAD_CRAWL_CSV/FinalOutputFolder
poll.frequency.millis=60000
input.file.prefix= LINKEDIN_URL_CRAWL_REQUEST_
output.file.prefix= LINKEDIN_LEAD_DATA_
onedrive.access.token=Bearer ey
mariadb.config=jdbc:mariadb://127.0.0.1:3306/AUTOMI_CRAWLER
mariadb.username=automi_crawler_admin
mariadb.password=automi_crawler_admin
json.array.profileurl.size=3
mail.sender.username=leadcrawlingservice@gmail.com
mail.sender.password=Admin@1234
input.path=/Users/mohitchhabra/Documents/LeadCrawlService/Input/
output.path=/Users/mohitchhabra/Documents/LeadCrawlService/Output/
payload.path=/Users/mohitchhabra/Documents/LeadCrawlService/PayLoads/SN_URL_
column.company.name=NAME
column.company.website=WEBSITE
download.base.url=http://172.16.28.186:5001/downloadfile/
slack.webhook.url=https://hooks.slack.com/services/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
email.generator.api=http://localhost:8006/v1/getReducedEmails
referrerfile.path=config/referrer.txt
useragent.path=config/user-agent.txt
user.agent.file.size=109
referrer.file.size=26
proxy.file.path=config/proxies.txt
number.of.pages=1
result.limit.for.companies=7
acronym.length.limit=5
country.code.file.path=config/countryCodes.csv
program.sleep.time = 120
load.balancer.api=http://localhost:7071/loadbalancer/getCrawledJson